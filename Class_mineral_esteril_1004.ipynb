{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vRjA6oB6_PdP"
      },
      "outputs": [],
      "source": [
        "# 1. Importar librerias\n",
        "from IPython import get_ipython #interfaz mejorada\n",
        "from IPython.display import display #interfaz mejorada de los outputs\n",
        "import tensorflow\n",
        "import sys\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import glob\n",
        "from imutils import paths # enlista archivos de una ruta dada en las carpetas y subcarpetas\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from google.colab import drive\n",
        "from tqdm import tqdm # muestra el  de avance cuando ejecutas un for in"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Montar Google Drive, en esa ruta debe estar la carpeta model_1 con las sub carpetas de fotos esteril, mineral\n",
        "drive.mount('/content/drive')\n",
        "workdir_path = 'drive/MyDrive/Colab Notebooks/mineral_esteril'\n",
        "os.chdir(workdir_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "gLYrVUQP_W0-",
        "outputId": "6a2364a7-8e42-43cc-dd84-3cc427c6940c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'drive/MyDrive/Colab Notebooks/mineral_esteril'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-b3f85c82aa04>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mworkdir_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'drive/MyDrive/Colab Notebooks/mineral_esteril'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkdir_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drive/MyDrive/Colab Notebooks/mineral_esteril'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define los hiperparámetros\n",
        "INIT_LR = 1e-3 # tasa de aprendizaje inicial, controla la velocidad con la que el modelo ajusta sus pesos durante el entrenamiento\n",
        "EPOCHS = 15 # número de épocas\n",
        "BS = 30 # tamaño del lote, numero de ejemplos de entrenamiento en cada iteracion\n",
        "dataset_path = 'model_1'\n",
        "\n",
        "\n",
        "# Carga las imágenes y las etiquetas\n",
        "print(\"[INFO] loading images...\")\n",
        "imagePaths = list(paths.list_images(dataset_path)) # lista de las imagenes con su ruta\n",
        "data = [] # lista donde se almaceneran las imagenes para entregar\n",
        "labels = [] # lista de la etiqueta de cada imagen\n",
        "\n",
        "for imagePath in tqdm(imagePaths, desc=\"\\tloading...\"):\n",
        "    label = imagePath.split(os.path.sep)[-2] # nombre de la carpeta de la imagen cargada, mineral o esteril\n",
        "    image = cv2.imread(imagePath) # leer imagen\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # convertir a formato rgb de tensorflow\n",
        "    image = cv2.resize(image, (224, 224))\n",
        "    data.append(image) #se añade la imagen a la lista data\n",
        "    labels.append(label)#se añade la etiqueta de la imagen a la lista data\n",
        "\n",
        "print(\"labels: \", np.unique(labels)) # verificar que esteril este primero y luego mineral, ya que nuestra identificacion sera en orden 0 esteril 1 mineral\n",
        "\n",
        "\n",
        "# Preprocesa los datos\n",
        "print(\"\\nlista data antes de la normalizacion:\\n\\n\",data[2][110][50:55]) # dato rgb de los pixeles de las columnas 50 a 54 de la fila 110 de la tercera foto\n",
        "data = np.array(data) / 255.0 # normalizar valores rgb de cada pixel de 0 a 1\n",
        "print(\"\\nlista data despues de la normalizacion:\\n\\n\",data[2][110][50:55])# dato rgb estandarizado de los pixeles de las columnas 50 a 54 de la fila 110 de la tercera foto\n",
        "labels = np.array(labels) # convierte la lista labels e un array de numpy\n",
        "lb = LabelBinarizer() # funcion que binariza\n",
        "labels = lb.fit_transform(labels) # transofmra categorias a binario\n",
        "labels = to_categorical(labels) # one hot encoding\n",
        "\n",
        "\n",
        "# Divide los datos en conjuntos de entrenamiento y prueba, se esta utilizando 80% para entregar y 20% para test\n",
        "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
        "                                                  test_size=0.20, stratify=labels, random_state=42)\n",
        "\n",
        "\n",
        "# Define el aumento de datos\n",
        "trainAug = ImageDataGenerator(\n",
        "    width_shift_range=0.1,# movimiendo horizontal aleatorio maximo en 10%\n",
        "    height_shift_range=0.1,# movimiendo vertical aleatorio maximo en 10%\n",
        "    zoom_range=0.1 #zoom aleatorio en 10%%\n",
        ")\n",
        "\n",
        "\n",
        "# Carga el modelo base VGG16\n",
        "baseModel = VGG16(weights=\"imagenet\", include_top=False,\n",
        "                  input_tensor=Input(shape=(224, 224, 3)))\n",
        "\n",
        "\n",
        "# Construye la cabeza del modelo\n",
        "headModel = baseModel.output\n",
        "headModel = MaxPooling2D(pool_size=(2, 2))(headModel)\n",
        "headModel = Flatten(name=\"flatten\")(headModel)\n",
        "headModel = Dense(128, activation=\"relu\")(headModel)#128 neuronas\n",
        "headModel = Dropout(0.2)(headModel)\n",
        "headModel = Dense(2, activation=\"softmax\")(headModel)\n",
        "\n",
        "\n",
        "# Combina el modelo base y la cabeza\n",
        "model = Model(inputs=baseModel.input, outputs=headModel)\n",
        "\n",
        "\n",
        "# Congela las capas del modelo base\n",
        "for layer in baseModel.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "# Compila el modelo\n",
        "print(\"[INFO] compiling model...\")\n",
        "opt = Adam(learning_rate=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6G9-r6Z_rPZ",
        "outputId": "24275c71-269a-4074-a299-5827a67f7008"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] loading images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tloading...: 100%|██████████| 10/10 [00:02<00:00,  4.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels:  ['esteril']\n",
            "lista data antes de la normalizacion:\n",
            " [[ 88  91  98]\n",
            " [ 86  90  99]\n",
            " [ 98 101 110]\n",
            " [ 95  95 107]\n",
            " [ 98  95 103]\n",
            " [ 49  44  51]\n",
            " [ 75  75  73]\n",
            " [ 94  95 100]\n",
            " [ 89  89  94]\n",
            " [ 79  80  86]]\n",
            "lista data despues de la normalizacion:\n",
            " [[0.34509804 0.35686275 0.38431373]\n",
            " [0.3372549  0.35294118 0.38823529]\n",
            " [0.38431373 0.39607843 0.43137255]\n",
            " [0.37254902 0.37254902 0.41960784]\n",
            " [0.38431373 0.37254902 0.40392157]\n",
            " [0.19215686 0.17254902 0.2       ]\n",
            " [0.29411765 0.29411765 0.28627451]\n",
            " [0.36862745 0.37254902 0.39215686]\n",
            " [0.34901961 0.34901961 0.36862745]\n",
            " [0.30980392 0.31372549 0.3372549 ]]\n",
            "[INFO] compiling model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py:86: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrena el modelo\n",
        "print(\"[INFO] training head...\")\n",
        "H = model.fit(trainAug.flow(trainX, trainY, batch_size=BS),\n",
        "        steps_per_epoch=len(trainX) // BS,\n",
        "        validation_data=(testX, testY),\n",
        "        validation_steps=len(testX) // BS,\n",
        "        epochs=EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYml2PmiA0uv",
        "outputId": "9880d72c-9e66-4502-bf9d-cc06b8497c0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] training head...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
            "Expected: ['keras_tensor']\n",
            "Received: inputs=Tensor(shape=(None, 224, 224, 3))\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m488s\u001b[0m 25s/step - accuracy: 0.7267 - loss: 0.6076 - val_accuracy: 0.7815 - val_loss: 0.4371\n",
            "Epoch 2/15\n",
            "\u001b[1m 1/20\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:13\u001b[0m 16s/step - accuracy: 0.8000 - loss: 0.3281"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 4s/step - accuracy: 0.8000 - loss: 0.3281 - val_accuracy: 0.7881 - val_loss: 0.4313\n",
            "Epoch 3/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m510s\u001b[0m 24s/step - accuracy: 0.8324 - loss: 0.4001 - val_accuracy: 0.8212 - val_loss: 0.4197\n",
            "Epoch 4/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 7s/step - accuracy: 0.8333 - loss: 0.4675 - val_accuracy: 0.8212 - val_loss: 0.4157\n",
            "Epoch 5/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m520s\u001b[0m 24s/step - accuracy: 0.8021 - loss: 0.4052 - val_accuracy: 0.8344 - val_loss: 0.3838\n",
            "Epoch 6/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 7s/step - accuracy: 0.8333 - loss: 0.4880 - val_accuracy: 0.8278 - val_loss: 0.3906\n",
            "Epoch 7/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m520s\u001b[0m 24s/step - accuracy: 0.8656 - loss: 0.3429 - val_accuracy: 0.8212 - val_loss: 0.3843\n",
            "Epoch 8/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 5s/step - accuracy: 0.7667 - loss: 0.4939 - val_accuracy: 0.8212 - val_loss: 0.3941\n",
            "Epoch 9/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m465s\u001b[0m 24s/step - accuracy: 0.8659 - loss: 0.3440 - val_accuracy: 0.8212 - val_loss: 0.3749\n",
            "Epoch 10/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 7s/step - accuracy: 0.8333 - loss: 0.4385 - val_accuracy: 0.8344 - val_loss: 0.3874\n",
            "Epoch 11/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m470s\u001b[0m 21s/step - accuracy: 0.8449 - loss: 0.3354 - val_accuracy: 0.8278 - val_loss: 0.3769\n",
            "Epoch 12/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 7s/step - accuracy: 0.8000 - loss: 0.3359 - val_accuracy: 0.8212 - val_loss: 0.3778\n",
            "Epoch 13/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m537s\u001b[0m 25s/step - accuracy: 0.8874 - loss: 0.2967 - val_accuracy: 0.7748 - val_loss: 0.4526\n",
            "Epoch 14/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 7s/step - accuracy: 1.0000 - loss: 0.0279 - val_accuracy: 0.7815 - val_loss: 0.4418\n",
            "Epoch 15/15\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m521s\u001b[0m 24s/step - accuracy: 0.8748 - loss: 0.3094 - val_accuracy: 0.8278 - val_loss: 0.3818\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evalúa el modelo\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predIdxs = model.predict(testX, batch_size=BS)\n",
        "predIdxs = np.argmax(predIdxs, axis=1)\n",
        "print(classification_report(testY.argmax(axis=1), predIdxs,\n",
        "                            target_names=lb.classes_))\n",
        "\n",
        "\n",
        "# Calcula la matriz de confusión\n",
        "cm = confusion_matrix(testY.argmax(axis=1), predIdxs)\n",
        "total = sum(sum(cm))\n",
        "acc = (cm[0, 0] + cm[1, 1]) / total\n",
        "sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
        "specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
        "print(cm)\n",
        "print(\"acc: {:.4f}\".format(acc))\n",
        "\n",
        "\n",
        "# Grafica la pérdida y la precisión del entrenamiento\n",
        "N = EPOCHS\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy on Testigos Yumpag\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Guarda el modelo\n",
        "tensorflow.keras.models.save_model(model, \"modelddh3.h5\")"
      ],
      "metadata": {
        "id": "mwjMIXh2A610"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carga el modelo guardado\n",
        "model_loaded = load_model(\"modelddh3.h5\")\n",
        "\n",
        "\n",
        "# Evalúa el modelo en el conjunto de prueba\n",
        "dataset_path = ['test/esteriles', 'test/minerales']# carpeta y subcarpetas de las imagenes nuevas a testear\n",
        "total_esteriles_predichos = 0\n",
        "total_minerales_predichos = 0\n",
        "total_esteriles_reales = 0\n",
        "total_minerales_reales = 0\n",
        "\n",
        "all_labels = [] # aqui se guardan los 0 y 1 de los labels orignales\n",
        "all_predictions = [] # aqui las predicciones\n",
        "\n",
        "for i in dataset_path: # se va recorrer la ruta, en este caso primero la subcarpeta esteriles de la carpeta test\n",
        "    print(\"[INFO] testing images:\", i)\n",
        "    mimagePaths = list(paths.list_images(i)) #se enlista todas las imagenes de la carpeta\n",
        "    mdata = [] #lista donde se almacenaran las imagenes formateadas para tensorflow\n",
        "    mlabels = []#lista donde se almacenaran el codigo binarizado de la foto del testo, 0 esteril 1 mineral\n",
        "    name_photo = []#lista del nombre de la foto\n",
        "\n",
        "    for imagePath in mimagePaths: #formatear imagenes a tensorflor\n",
        "        name = os.path.basename(imagePath)#nombre de la imagen\n",
        "        mimage = cv2.imread(imagePath)#leer la imagen\n",
        "        mimage = cv2.cvtColor(mimage, cv2.COLOR_BGR2RGB)#convertir el formato de la imagen a rgb\n",
        "        mimage = cv2.resize(mimage, (224, 224)) #redimensionar la imagen a las mismas dimensiones de las fotos que se usaron para el entrenamiento\n",
        "        mdata.append(mimage) # se añade la foto formateada a la lista mdata vacia de arriba\n",
        "        name_photo.append(name)# se añade el nombre de la foto a la lista name_photo vacia de arriba\n",
        "        label = 0 if i == \"test/esteriles\" else 1 # se indica 0 si el nombre de la carpeta de la imagen es esteril, sino es 1\n",
        "        mlabels.append(label)# se añade el codigo 0 o 1 a la lista mlabels vacia de arriba\n",
        "\n",
        "    mdata = np.array(mdata) / 255.0 # la lista de imagenes se tranforma a una lista de numpy y luego se estandariza de 0 a 1\n",
        "    predIdxs = model_loaded.predict(mdata, batch_size=1) #prediccion de la lista mdata de imagenes formateadas procesando una imagen a la vez (batchsize)\n",
        "    # la lista predIdxs tiene el siguiente formato:\n",
        "    #  [[0.95, 0.05], Predicción para la imagen 1, aqui indica que 95% probabilidad es que sea esteril y 5% mineral\n",
        "    #   [0.10, 0.90]]  Predicción para la imagen 2, aqui indica que 10% probabilidad es que sea esteril y 90% mineral\n",
        "    print(\"\\n\\nlista predIdxs original en\",i,\":\\n\",predIdxs[:4])\n",
        "    predIdxs = np.argmax(predIdxs, axis=1)#aqui seleccionas el indice de cada lista con el nro mayor de probabilidad, en una sola lista segun el ejemplo de arriba seria [0, 1]\n",
        "    print(\"\\nlista predIdxs con el indice de mayor probabilidad 0 esteril 1 mineral:\\n\",predIdxs[:4],\"\\n\")\n",
        "    all_labels.extend(mlabels)# se añaden la lista de los labels originales a la lista total 0 y 1\n",
        "    all_predictions.extend(predIdxs)# se añaden la lista de las predicciones\n",
        "\n",
        "    if i == \"test/esteriles\":#esto solo es para verificar el nro total de imagenes cargadas vs lo predicho\n",
        "        # resta el total de fotos evaluadas menos la suma de predicciones\n",
        "        # si todas las imagenes en esta parte fueran esteriles significa que la sumatoria de predIdx seria 0 y el resultado seria 100% de acierto\n",
        "        esteriles_predichos = len(predIdxs) - np.sum(predIdxs)\n",
        "        total_esteriles_predichos += esteriles_predichos\n",
        "        total_esteriles_reales += len(mlabels)\n",
        "    else:\n",
        "        # como minerales tiene 1 de prediccion cuando es correcta, el numero de fotos acertadas es la suma de predIdxs\n",
        "        minerales_predichos = np.sum(predIdxs)\n",
        "        total_minerales_predichos += minerales_predichos\n",
        "        total_minerales_reales += len(mlabels)\n",
        "\n",
        "\n",
        "# Calcula las métricas de evaluación\n",
        "precision_esteriles = precision_score(all_labels, all_predictions, pos_label=0)\n",
        "precision_minerales = precision_score(all_labels, all_predictions, pos_label=1)\n",
        "recall_esteriles = recall_score(all_labels, all_predictions, pos_label=0)\n",
        "recall_minerales = recall_score(all_labels, all_predictions, pos_label=1)\n",
        "f1_esteriles = f1_score(all_labels, all_predictions, pos_label=0)\n",
        "f1_minerales = f1_score(all_labels, all_predictions, pos_label=1)\n",
        "\n",
        "print(f\"Precisión para esteriles: {precision_esteriles * 100:.2f}%\")\n",
        "print(f\"Precisión para minerales: {precision_minerales * 100:.2f}%\")\n",
        "print(f\"Recall para esteriles: {recall_esteriles * 100:.2f}%\")\n",
        "print(f\"Recall para minerales: {recall_minerales * 100:.2f}%\")\n",
        "print(f\"F1-score para esteriles: {f1_esteriles * 100:.2f}%\")\n",
        "print(f\"F1-score para minerales: {f1_minerales * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJdhhohuBAIU",
        "outputId": "1f8ed3f0-fbde-410e-b12e-766a1a28b6ed"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] testing images: test/esteriles\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 576ms/step\n",
            "\n",
            "\n",
            "lista predIdxs original en test/esteriles :\n",
            " [[9.9999011e-01 9.8712226e-06]\n",
            " [9.9997652e-01 2.3432041e-05]\n",
            " [9.9965370e-01 3.4631338e-04]\n",
            " [9.9999726e-01 2.7144736e-06]]\n",
            "\n",
            "lista predIdxs con el indice de mayor probabilidad 0 esteril 1 mineral:\n",
            " [0 0 0 0] \n",
            "\n",
            "[INFO] testing images: test/minerales\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 571ms/step\n",
            "\n",
            "\n",
            "lista predIdxs original en test/minerales :\n",
            " [[1.5294567e-01 8.4705436e-01]\n",
            " [7.7250379e-01 2.2749622e-01]\n",
            " [9.9394339e-01 6.0566240e-03]\n",
            " [6.0236850e-04 9.9939764e-01]]\n",
            "\n",
            "lista predIdxs con el indice de mayor probabilidad 0 esteril 1 mineral:\n",
            " [1 0 0 1] \n",
            "\n",
            "Precisión para esteriles: 80.95%\n",
            "Precisión para minerales: 100.00%\n",
            "Recall para esteriles: 100.00%\n",
            "Recall para minerales: 63.64%\n",
            "F1-score para esteriles: 89.47%\n",
            "F1-score para minerales: 77.78%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bkELRv92OpKZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}